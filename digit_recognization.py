# -*- coding: utf-8 -*-
"""deeplearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IfaenGspqUtFteMcj3KAPx7KTGLt1qmM
"""

#importing keras from tensorflow
import tensorflow as tf
from tensorflow import keras

#loading mnist dataset(number pictures in form of numerical representations)
(trainx, trainy), (testx, testy)=keras.datasets.mnist.load_data()

print(testy.shape)

trainx_copy=trainx
testx_copy=testx

#converting trainx into single dimensional data
trainx=trainx.reshape(60000,784)
testx=testx.reshape(10000,784)

#parameter tuning
trainx=trainx.astype("float32")
testx=testx.astype("float32")
trainx/=255
testx/=255

print(trainx.shape,testx.shape,testy.shape)
#instanting model
model=keras.models.Sequential();

#printing the handwritten digit
import matplotlib.pyplot as plt
plt.imshow(trainx_copy[10],cmap=plt.get_cmap('ocean'))

#constructing model
model.add(keras.layers.Dense(10,input_shape=(784,),name="output",activation="softmax"));

#description about the built model
model.summary()

model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])

#one hot encoding
trainy=keras.utils.to_categorical(trainy,10)
testy=keras.utils.to_categorical(testy,10)

model.fit(trainx,trainy,verbose=1,batch_size=128,epochs=100)

print(testx.shape)
print(testy.shape)

(test_loss,test_accuracy)=model.evaluate(testx,testy)

print("accuracy of the model: "+str(test_accuracy))
print("loss impacted: "+str(test_loss))

#prediction
plt.imshow(testx_copy[9],cmap=plt.get_cmap('ocean'))

labels=model.predict(testx)

#the labels[1] should be 9!
print(labels[1]) #which is the probability value for all the nine digits out of that we have to identify the maximum probability

import numpy as np
print(np.argmax(labels[9]))
